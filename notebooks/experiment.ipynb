{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.perspective import four_point_transform\n",
    "from skimage.filters import threshold_local\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import imutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_PATH = os.path.join(os.path.abspath(\"..\"),\"artifacts\")\n",
    "models_path = os.path.join(ARTIFACT_PATH,\"models\")\n",
    "results_path = os.path.join(ARTIFACT_PATH,\"results\",\"License_Plate\")\n",
    "samples_path = os.path.join(ARTIFACT_PATH,\"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edge Detection\n"
     ]
    }
   ],
   "source": [
    "image = cv.imread(os.path.join(results_path,\"plate0.jpg\"))\n",
    "ratio = image.shape[0]/150\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height=150)\n",
    "\n",
    "gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "gray = cv.GaussianBlur(gray, (5,5), 0)\n",
    "edged = cv.Canny(gray, 150, 255)\n",
    "\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "cv.imshow(\"Image\", image)\n",
    "cv.imshow(\"Edged\", edged)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Find contours of paper\n"
     ]
    }
   ],
   "source": [
    "cnts = cv.findContours(edged.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv.contourArea, reverse = True)[:5]\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv.arcLength(c, True)\n",
    "\tapprox = cv.approxPolyDP(c, 0.02 * peri, True)\n",
    "\t# if our approximated contour has four points, then we\n",
    "\t# can assume that we have found our screen\n",
    "\tif len(approx) == 4:\n",
    "\t\tscreenCnt = approx\n",
    "\t\tbreak\n",
    "# show the contour (outline) of the piece of paper\n",
    "print(\"STEP 2: Find contours of paper\")\n",
    "cv.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv.imshow(\"Outline\", image)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Apply perspective transform\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv.cvtColor(warped, cv.COLOR_BGR2GRAY)\n",
    "# T = threshold_local(warped, 11, offset = 10, method = \"gaussian\")\n",
    "# warped = (warped > T).astype(\"uint8\") * 255\n",
    "# show the original and scanned images\n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "cv.imshow(\"Original\", imutils.resize(orig, height = 50))\n",
    "cv.imshow(\"Scanned\", imutils.resize(warped, height = 50))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "# save_path = os.path.join(ARTIFACT_PATH,\"results\",\"cropped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: Apply Histogram equalization\n"
     ]
    }
   ],
   "source": [
    "# Apply histogram equalization\n",
    "equalized_image = cv.equalizeHist(warped)\n",
    "\n",
    "print(\"STEP 4: Apply Histogram equalization\")\n",
    "cv.imshow(\"Scanned\", imutils.resize(equalized_image, height = 50))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width = equalized_image.shape[:2]\n",
    "clip_rows = int(0.2 * height)\n",
    "\n",
    "# Clip the top and bottom rows\n",
    "clipped_image = equalized_image[clip_rows:-clip_rows, :]\n",
    "clipped_image_no_hist = warped[clip_rows:-clip_rows, :]\n",
    "\n",
    "# Display or save the clipped image\n",
    "# cv.imshow('Clipped Image', imutils.resize(clipped_image, height = 50))\n",
    "cv.imshow('Clipped Image', clipped_image)\n",
    "cv.imshow('Clipped Image no hist', imutils.resize(clipped_image_no_hist, height = 50))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "cv.imwrite(os.path.join(ARTIFACT_PATH,\"results\", \"clipped.jpg\"),clipped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# Perform text detection and recognition on the PIL image\n",
    "result = reader.readtext(clipped_image)\n",
    "\n",
    "# Print the recognized text\n",
    "for detection in result:\n",
    "    print(detection[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anprenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
